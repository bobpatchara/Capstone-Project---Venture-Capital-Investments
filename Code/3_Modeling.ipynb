{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4c1157",
   "metadata": {},
   "source": [
    "## Capstone Project - Startup Investments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea79103",
   "metadata": {},
   "source": [
    "### Part 3 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f527e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data handling Libraries ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Plotting Libraries ###\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "## Date Time ###\n",
    "import datetime\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "### Warnings ###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### Progress Bar ###\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Model Building, Model Evaluvation, Model Preprocessing ###\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict,RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import VarianceThreshold,RFECV\n",
    "\n",
    "### Models Imbalance #\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# ML MODELS #\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Scoring Dependancies #\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "# from sklearn.metrics import average_precision_score,make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Models Saving #\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Other #\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d36929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db710663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/data_eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f98dc8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status                                0\n",
       "funding_rounds                        0\n",
       "seed                                  0\n",
       "venture                               0\n",
       "equity_crowdfunding                   0\n",
       "undisclosed                           0\n",
       "convertible_note                      0\n",
       "debt_financing                        0\n",
       "grant                                 0\n",
       "private_equity                        0\n",
       "post_ipo_equity                       0\n",
       "post_ipo_debt                         0\n",
       "secondary_market                      0\n",
       "product_crowdfunding                  0\n",
       "round_A                               0\n",
       "round_B                               0\n",
       "round_C                               0\n",
       "round_D                               0\n",
       "round_E                               0\n",
       "round_F                               0\n",
       "round_G                               0\n",
       "round_H                               0\n",
       "f_SumCol                              0\n",
       "f_market_Software                     0\n",
       "f_market_Biotechnology                0\n",
       "f_market_Mobile                       0\n",
       "f_market_E-Commerce                   0\n",
       "f_market_Curated Web                  0\n",
       "f_market_Mass Customization           0\n",
       "f_market_Computer Vision              0\n",
       "f_market_QR Codes                     0\n",
       "f_market_Women                        0\n",
       "f_market_Oil                          0\n",
       "f_market_Content Creators             0\n",
       "f_market_Oil and Gas                  0\n",
       "f_market_Babies                       0\n",
       "f_market_Content Delivery             0\n",
       "f_market_Unifed Communications        0\n",
       "f_market_Digital Rights Management    0\n",
       "f_market_Quantified Self              0\n",
       "f_market_Young Adults                 0\n",
       "f_market_Vending and Concessions      0\n",
       "f_market_Enterprise Purchasing        0\n",
       "f_country_code_USA                    0\n",
       "f_country_code_GBR                    0\n",
       "f_country_code_CAN                    0\n",
       "f_country_code_CHN                    0\n",
       "f_country_code_FRA                    0\n",
       "f_country_code_EGY                    0\n",
       "f_country_code_LUX                    0\n",
       "f_country_code_KEN                    0\n",
       "f_country_code_NGA                    0\n",
       "f_country_code_DZA                    0\n",
       "f_country_code_PER                    0\n",
       "f_country_code_ROM                    0\n",
       "f_country_code_LTU                    0\n",
       "f_country_code_PHL                    0\n",
       "f_country_code_COL                    0\n",
       "f_country_code_TTO                    0\n",
       "f_country_code_OMN                    0\n",
       "f_country_code_MUS                    0\n",
       "f_country_code_ZWE                    0\n",
       "f_country_code_LIE                    0\n",
       "f_region_SF Bay Area                  0\n",
       "f_region_New York City                0\n",
       "f_region_Boston                       0\n",
       "f_region_London                       0\n",
       "f_region_Los Angeles                  0\n",
       "f_region_Manaus                       0\n",
       "f_region_Lyngby                       0\n",
       "f_region_DE - Other                   0\n",
       "f_region_State College                0\n",
       "f_region_Verona                       0\n",
       "f_region_LUX - Other                  0\n",
       "f_region_Medellin                     0\n",
       "f_region_Pozuelo De Alarcon           0\n",
       "f_region_Swansea                      0\n",
       "f_region_Martinsried                  0\n",
       "f_region_Salzburg                     0\n",
       "f_region_ROM - Other                  0\n",
       "f_region_Pamplona                     0\n",
       "f_region_Salford                      0\n",
       "f_region_Coimbatore                   0\n",
       "f_Multi_Category                      0\n",
       "f_URL                                 0\n",
       "f_age                                 0\n",
       "f_yearstoFirstFunding                 0\n",
       "f_FirstFundingToLastFunding           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d436f87",
   "metadata": {},
   "source": [
    "## Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933d7c4",
   "metadata": {},
   "source": [
    "Since our model requires the target variable to be numeric, the below block of code converts categorical target variable to numerical target variable using label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "29919303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    33652\n",
       "0     3134\n",
       "1     2134\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14706936",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding Target Variable ### \n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "df['status']= label_encoder.fit_transform(df['status']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c13c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the final dataset : 38920 \n",
      "Total number of columns in the final dataset : 88\n"
     ]
    }
   ],
   "source": [
    "ROWS = df.shape[0]\n",
    "COLUMNS = df.shape[1]\n",
    "print(f'Total number of rows in the final dataset : {ROWS} \\nTotal number of columns in the final dataset : {COLUMNS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73a103",
   "metadata": {},
   "source": [
    "Originally, we had 54249 rows and 39 features in our data set and finally after data preprocessing and feature engineering we have 38920 records with 88 features in the final data set. We will later perform data augmentation to address class imbalance to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800299c",
   "metadata": {},
   "source": [
    "#### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48de8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN TEST SPLIT ###\n",
    "X = df.loc[:, ~df.columns.isin(['status'])] \n",
    "y = df.loc[:, ['status']] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e067fdd",
   "metadata": {},
   "source": [
    "#### Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be1a10",
   "metadata": {},
   "source": [
    "Since this is data set is a highly imbalanced data set **accuracy** **((TP+TN)/(TP+TN+FP+FN))** will not be a good evaluation metric and hence in this project we will be using **F1-score** which is the harmonic mean value of precession (Out of the total positively predicted value how many are actually positive values **((TP)/(TP+FP))** and recall (Out of the actual positive values how many were correctly predicted as positive **((TP)/(TP+FN))**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09631eef",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004c150",
   "metadata": {},
   "source": [
    "## Dummay Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72297c1",
   "metadata": {},
   "source": [
    "The primary reason for using a dummy variable model is to compare the evaluation scores obtained by this model against the evaluation scores obtained by the actual model that you will be building. \n",
    "\n",
    "If the evaluation score built by your model is less than that of the dummy model then we need to definitely rethink about either fine tuning our existing model or building a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf1fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f7bff",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa048f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20936afa",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99530c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted the values\n"
     ]
    }
   ],
   "source": [
    "predictedValues = dummy_clf.predict(X_test)\n",
    "print('Sucessfully predicted the values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37b604c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcCustomCVScore(fncp_X_train, fncp_y_train, fncpKFold,fncpBaseModel, fncpBaseModelParam=None, fncpRandomState=None, fncpScoreAverage='weighted'):\n",
    "\n",
    "  '''\n",
    "  This function splits the X_train and y_train into folds for cross calulating recall, precesion and f1 score's of each fold and returns the scores \n",
    "  and prints the mean score and the 95% confidence interval of the score estimate.\n",
    "\n",
    "  input:\n",
    "     fncp_X_train - X_train\n",
    "     fncp_y_train - y_train\n",
    "     fncpKFold - No of folds\n",
    "     fncpBaseModel - Base model. Ex: RandomForestClassifier\n",
    "     (Optional) (dict) - Parameters to be used in the base model\n",
    "     (Optional)  fncpRandomState\n",
    "     (Optional) fncpScoreAverage\n",
    "  output:\n",
    "    recallScores\n",
    "    precisionScores\n",
    "    f1Scores\n",
    "\n",
    "  '''\n",
    "  kfold = KFold(n_splits=fncpKFold, random_state=fncpRandomState)\n",
    "  recallScores = []\n",
    "  precisionScores = []\n",
    "  f1Scores = []\n",
    "  for train_index, test_index in tqdm(kfold.split(fncp_X_train)):\n",
    "    cv_X_train = fncp_X_train[fncp_X_train.index.isin(train_index)]\n",
    "    cv_X_test = fncp_X_train[fncp_X_train.index.isin(test_index)]\n",
    "\n",
    "    cv_y_train = fncp_y_train[fncp_y_train.index.isin(train_index)]\n",
    "    cv_y_test = fncp_y_train[fncp_y_train.index.isin(test_index)]\n",
    "\n",
    "    if fncpBaseModelParam == None:\n",
    "      model = fncpBaseModel()\n",
    "    else:\n",
    "      model = fncpBaseModel(**fncpBaseModelParam)\n",
    "    model.fit(cv_X_train,cv_y_train)\n",
    "\n",
    "    tempScore = round(recall_score(cv_y_test, model.predict(cv_X_test), average=fncpScoreAverage)*100,2)\n",
    "    precisionScores.append(tempScore)\n",
    "\n",
    "    tempScore = round(precision_score(cv_y_test, model.predict(cv_X_test), average=fncpScoreAverage)*100,2)\n",
    "    recallScores.append(tempScore)\n",
    "\n",
    "    tempScore = round(f1_score(cv_y_test, model.predict(cv_X_test), average=fncpScoreAverage)*100,2)\n",
    "    f1Scores.append(tempScore)\n",
    "  print('\\n')\n",
    "  print(f'The mean score and the 95% confidence interval of the score estimate are')\n",
    "  print(\"Recall: %0.2f (+/- %0.2f)\" % (np.array(recallScores).mean(), np.array(recallScores).std() * 2))\n",
    "  print(\"Precision: %0.2f (+/- %0.2f)\" % (np.array(precisionScores).mean(), np.array(precisionScores).std() * 2))\n",
    "  print(\"F1-Score: %0.2f (+/- %0.2f)\" % (np.array(f1Scores).mean(), np.array(f1Scores).std() * 2))\n",
    "  return recallScores, precisionScores, f1Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f30b75c",
   "metadata": {},
   "source": [
    "#### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc7f0082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 52.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The mean score and the 95% confidence interval of the score estimate are\n",
      "Recall: 74.89 (+/- 2.84)\n",
      "Precision: 86.53 (+/- 1.65)\n",
      "F1-Score: 80.29 (+/- 2.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recallScores, precisionScores, f1Scores = funcCustomCVScore(fncp_X_train=X_train, \n",
    "                                                            fncp_y_train=y_train, \n",
    "                                                            fncpKFold=10,\n",
    "                                                            fncpBaseModel=DummyClassifier,\n",
    "                                                            fncpBaseModelParam={'strategy':'most_frequent'},\n",
    "                                                            fncpScoreAverage='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfff588",
   "metadata": {},
   "source": [
    "#### Test Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95438c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fncpModelEvaluvate(fncpActual, fncpPredicted, fncpBoolHeatMap=False, fncpMultiClass=True,fncpAverageType='weighted'):\n",
    "  '''\n",
    "  This function prints the various evaluvation metric of a models and also prints the confusion matrix\n",
    "  input:\n",
    "    fncpActual - Actual Values\n",
    "    funPredictedValues - Predicted Values\n",
    "    (optional) (bool) fncpBoolHeatMap - To display or not display confusion matrix\n",
    "    (optional) (bool) fncpMultiClass - Is it a multiclass problem or binary class problem\n",
    "    (optional) (bool) fncpAverageType - Average type for multiclass problem   \n",
    "  '''\n",
    "\n",
    "  # Heat Map #\n",
    "  if  fncpBoolHeatMap == True:\n",
    "    cf_matrix = confusion_matrix(fncpActual, fncpPredicted)\n",
    "    make_confusion_matrix(cf_matrix, figsize=(8,6), cbar=True, cmap='BrBG')\n",
    "    print('\\n\\n')\n",
    "\n",
    "  print('Evaluation Metrics\\n')\n",
    "  # print(f'Accuracy Score :{round(accuracy_score(fncpActual, fncpPredicted)*100,2)}%')\n",
    "  if fncpMultiClass == True:\n",
    "    print(f'Recall Score :{round(recall_score(fncpActual, fncpPredicted, average=fncpAverageType)*100,2)}%')\n",
    "    print(f'Precision Score :{round(precision_score(fncpActual, fncpPredicted, average=fncpAverageType)*100,2)}%')\n",
    "    print(f'F1 Score :{round(f1_score(fncpActual, fncpPredicted, average=fncpAverageType)*100,2)}%')\n",
    "  else:\n",
    "    print(f'Recall Score :{round(recall_score(fncpActual, fncpPredicted)*100,2)}%')\n",
    "    print(f'Precision Score :{round(precision_score(fncpActual, fncpPredicted)*100,2)}%')\n",
    "    print(f'F1 Score :{round(f1_score(fncpActual, fncpPredicted)*100,2)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "df6e420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "\n",
      "Recall Score :80.7%\n",
      "Precision Score :80.79%\n",
      "F1 Score :80.74%\n"
     ]
    }
   ],
   "source": [
    "fncpModelEvaluvate(fncpActual=y_test, \n",
    "                   fncpPredicted=predictedValues, \n",
    "                   fncpBoolHeatMap=False, \n",
    "                   fncpMultiClass=True,\n",
    "                   fncpAverageType='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704ecac",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2f5be",
   "metadata": {},
   "source": [
    "Random Forest is a powerful decision tree ensemble model that can be used for both regression and classification model. I have used this model since it is easy to interpret and Random Forest model will be not affected by multi-collinearity problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4816c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classiRandomForest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9a489b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted the values\n"
     ]
    }
   ],
   "source": [
    "classiRandomForest.fit(X_train, y_train)\n",
    "predictedValues = classiRandomForest.predict(X_test)\n",
    "print('Sucessfully predicted the values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f442b58",
   "metadata": {},
   "source": [
    "#### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0222061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:11,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The mean score and the 95% confidence interval of the score estimate are\n",
      "Recall: 80.58 (+/- 1.69)\n",
      "Precision: 84.80 (+/- 1.07)\n",
      "F1-Score: 82.20 (+/- 1.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recallScores, precisionScores, f1Scores = funcCustomCVScore(fncp_X_train=X_train, \n",
    "                                                            fncp_y_train=y_train, \n",
    "                                                            fncpKFold=10,\n",
    "                                                            fncpBaseModel=RandomForestClassifier,\n",
    "                                                            fncpBaseModelParam=None,\n",
    "                                                            fncpScoreAverage='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3e1c4",
   "metadata": {},
   "source": [
    "#### Test Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f91a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "\n",
      "Recall Score :83.88%\n",
      "Precision Score :79.39%\n",
      "F1 Score :81.14%\n"
     ]
    }
   ],
   "source": [
    "fncpModelEvaluvate(fncpActual=y_test, \n",
    "                   fncpPredicted=predictedValues, \n",
    "                   fncpBoolHeatMap=False, \n",
    "                   fncpMultiClass=True,\n",
    "                   fncpAverageType='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e73e2f",
   "metadata": {},
   "source": [
    "### Random Forest with optimum parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81913618",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters are \n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(f'The hyperparameters are \\n{random_grid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d7acf",
   "metadata": {},
   "source": [
    "#### Random Search CV Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c012147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start time : 27042021_134649\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Minutes taken to complete training : 23.445099218686423\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = RandomForestClassifier()\n",
    "current_time = datetime.datetime.now(pytz.timezone('Asia/Bangkok')).strftime(\"%d%m%Y_%H%M%S\")\n",
    "modelFileName = 'cv_model_'+ current_time +'.sav'\n",
    "print(f'Model training start time : {current_time}\\n')\n",
    "rf_random = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=100, cv=3, verbose=3, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Saving Model #\n",
    "pickle.dump(rf_random, open(modelFileName, 'wb'))\n",
    "\n",
    "print(f'Minutes taken to complete training : {(time.time() - start_time)/60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "874ec2d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully loaded the model!!!\n"
     ]
    }
   ],
   "source": [
    "### Loading saved model ###\n",
    "chosenFilePath = 'cv_model_27042021_134649.sav'\n",
    "loaded_model = pickle.load(open(chosenFilePath, 'rb'))\n",
    "print('Sucessfully loaded the model!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6aae8c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best \"n_estimators\" hyperparameter is: 600 \n",
      "The best \"min_samples_split\" hyperparameter is: 10 \n",
      "The best \"min_samples_leaf\" hyperparameter is: 2 \n",
      "The best \"max_features\" hyperparameter is: auto \n",
      "The best \"max_depth\" hyperparameter is: 100 \n",
      "The best \"bootstrap\" hyperparameter is: True \n"
     ]
    }
   ],
   "source": [
    "for key, val in loaded_model.best_params_.items():\n",
    "  print(f'The best \"{key}\" hyperparameter is: {val} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f3ac370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcFeatureImportance(fncpModel, fncpTrainSet, fncpCV=True):\n",
    "\n",
    "  '''\n",
    "  This function prints the top 20 and bottom 20 important features and returns an dataframe with important features sorted in descending order\n",
    "  input:\n",
    "    (model) fncpModel\n",
    "    (dataframe) fncpTrainSet\n",
    "    (optional) (bool) fncpCV\n",
    "  ouput:\n",
    "    dataframe\n",
    "  '''\n",
    "  if fncpCV == True:\n",
    "    feature_importances = pd.DataFrame(fncpModel.best_estimator_.feature_importances_,\n",
    "                                      index = fncpTrainSet.columns,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "  else:\n",
    "    feature_importances = pd.DataFrame(fncpModel.feature_importances_,\n",
    "                              index = fncpTrainSet.columns,\n",
    "                                columns=['importance']).sort_values('importance', ascending=False)                         \n",
    "  print(\"Top 20 Important Feature\\n\")\n",
    "  print(feature_importances.head(20))\n",
    "  print('\\n')\n",
    "  print(\"Bottom 20 Important Feature\\n\")\n",
    "  print(feature_importances.tail(20))\n",
    "  return feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40011cd",
   "metadata": {},
   "source": [
    "The top 5 most important features are as below and as you can clearly see most of the features in the below list are engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8aa161c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Important Feature\n",
      "\n",
      "                             importance\n",
      "f_age                          0.306243\n",
      "f_SumCol                       0.170225\n",
      "f_yearstoFirstFunding          0.163984\n",
      "venture                        0.114485\n",
      "f_FirstFundingToLastFunding    0.091677\n",
      "seed                           0.070807\n",
      "f_country_code_USA             0.027797\n",
      "funding_rounds                 0.024087\n",
      "f_Multi_Category               0.021045\n",
      "f_URL                          0.009652\n",
      "private_equity                 0.000000\n",
      "f_country_code_TTO             0.000000\n",
      "f_region_Boston                0.000000\n",
      "f_region_New York City         0.000000\n",
      "f_region_SF Bay Area           0.000000\n",
      "f_country_code_LIE             0.000000\n",
      "f_country_code_ZWE             0.000000\n",
      "f_country_code_MUS             0.000000\n",
      "f_country_code_OMN             0.000000\n",
      "f_country_code_COL             0.000000\n",
      "\n",
      "\n",
      "Bottom 20 Important Feature\n",
      "\n",
      "                                    importance\n",
      "f_market_Computer Vision                   0.0\n",
      "f_country_code_FRA                         0.0\n",
      "f_market_Quantified Self                   0.0\n",
      "f_country_code_CHN                         0.0\n",
      "f_country_code_CAN                         0.0\n",
      "convertible_note                           0.0\n",
      "debt_financing                             0.0\n",
      "f_market_Enterprise Purchasing             0.0\n",
      "f_market_Vending and Concessions           0.0\n",
      "f_market_Young Adults                      0.0\n",
      "f_market_Digital Rights Management         0.0\n",
      "f_market_QR Codes                          0.0\n",
      "f_market_Unifed Communications             0.0\n",
      "f_market_Content Delivery                  0.0\n",
      "f_market_Babies                            0.0\n",
      "f_market_Oil and Gas                       0.0\n",
      "f_market_Content Creators                  0.0\n",
      "f_market_Oil                               0.0\n",
      "f_market_Women                             0.0\n",
      "f_country_code_GBR                         0.0\n"
     ]
    }
   ],
   "source": [
    "### Feature Importance ###\n",
    "dfImportantFeature = funcFeatureImportance(loaded_model, X_train, fncpCV=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eedad3",
   "metadata": {},
   "source": [
    "As in the previous cases we calculate recall, precision, and F1-score for predictions made on cross validated training data set and also calculate the scores for predictions made on the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53f079",
   "metadata": {},
   "source": [
    "#### Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "960b5e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:57,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The mean score and the 95% confidence interval of the score estimate are\n",
      "Recall: 82.49 (+/- 3.75)\n",
      "Precision: 86.80 (+/- 1.58)\n",
      "F1-Score: 81.89 (+/- 2.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recallScores, precisionScores, f1Scores = funcCustomCVScore(fncp_X_train=X_train, \n",
    "                                                            fncp_y_train=y_train, \n",
    "                                                            fncpKFold=10,\n",
    "                                                            fncpBaseModel=RandomForestClassifier, \n",
    "                                                            fncpBaseModelParam=loaded_model.best_params_,\n",
    "                                                            fncpScoreAverage='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1dbfb8",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e545c85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted the values\n"
     ]
    }
   ],
   "source": [
    "predictedValues = loaded_model.best_estimator_.predict(X_test)\n",
    "print('Sucessfully predicted the values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507dc239",
   "metadata": {},
   "source": [
    "#### Test Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1326f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "\n",
      "Recall Score :85.84%\n",
      "Precision Score :78.88%\n",
      "F1 Score :80.66%\n"
     ]
    }
   ],
   "source": [
    "# Test Dataset\n",
    "\n",
    "fncpModelEvaluvate(y_test, predictedValues, fncpBoolHeatMap=False, fncpMultiClass=True,fncpAverageType='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc36911",
   "metadata": {},
   "source": [
    "## Treating Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3476a1e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before under and over SMOTE\n",
      "Counter({2: 26954, 0: 2476, 1: 1706})\n",
      "\n",
      "\n",
      "After under and over SMOTE\n",
      "Counter({2: 20000, 0: 12000, 1: 12000})\n",
      "\n",
      "SMOTE dataframe sucessfully created\n"
     ]
    }
   ],
   "source": [
    "print('Before under and over SMOTE')\n",
    "counter = Counter(y_train['status'].array)\n",
    "print(counter)\n",
    "\n",
    "# define pipeline\n",
    "dictOver = {0: 12000, 1:12000}\n",
    "over = SMOTE(sampling_strategy=dictOver)\n",
    "dictUnder = {2: 20000}\n",
    "under = RandomUnderSampler(sampling_strategy=dictUnder)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_new, y_new = pipeline.fit_resample(X_train, y_train)\n",
    "X_new, y_new = shuffle(X_new, y_new) # Shuffles the arrays\n",
    "\n",
    "print('\\n')\n",
    "print('After under and over SMOTE')\n",
    "counter = Counter(y_new['status'].array)\n",
    "print(counter)\n",
    "\n",
    "# Converts the array into a dataframe \n",
    "X_new = pd.DataFrame(data=X_new, columns=X_train.columns.to_list())\n",
    "y_new = pd.DataFrame(data=y_new, columns=y_train.columns.to_list())\n",
    "print('\\nSMOTE dataframe sucessfully created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230d2de",
   "metadata": {},
   "source": [
    "## Dummy Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6fc0afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579900",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4f2029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.fit(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b123d",
   "metadata": {},
   "source": [
    "#### Most Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f6ecf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted the values\n"
     ]
    }
   ],
   "source": [
    "predictedValues = dummy_clf.predict(X_test)\n",
    "print('Sucessfully predicted the values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d737e",
   "metadata": {},
   "source": [
    "#### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9b44ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 77.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The mean score and the 95% confidence interval of the score estimate are\n",
      "Recall: 42.98 (+/- 94.69)\n",
      "Precision: 45.45 (+/- 94.48)\n",
      "F1-Score: 43.85 (+/- 94.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recallScores, precisionScores, f1Scores = funcCustomCVScore(fncp_X_train=X_new, \n",
    "                                                            fncp_y_train=y_new, \n",
    "                                                            fncpKFold=10,\n",
    "                                                            fncpBaseModel=DummyClassifier,\n",
    "                                                            fncpBaseModelParam={'strategy':'most_frequent'},\n",
    "                                                            fncpScoreAverage='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe528a8",
   "metadata": {},
   "source": [
    "#### Test Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2372d477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "\n",
      "Recall Score :86.05%\n",
      "Precision Score :74.04%\n",
      "F1 Score :79.6%\n"
     ]
    }
   ],
   "source": [
    "fncpModelEvaluvate(fncpActual=y_test, \n",
    "                   fncpPredicted=predictedValues, \n",
    "                   fncpBoolHeatMap=False, \n",
    "                   fncpMultiClass=True,\n",
    "                   fncpAverageType='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a4363",
   "metadata": {},
   "source": [
    "## Random Forest Classifer - Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11b66270",
   "metadata": {},
   "outputs": [],
   "source": [
    "classiRandomForest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5812c",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6cfd64e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classiRandomForest.fit(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53358d78",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05995258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted the values\n"
     ]
    }
   ],
   "source": [
    "predictedValues = classiRandomForest.predict(X_test)\n",
    "print('Sucessfully predicted the values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a9e39",
   "metadata": {},
   "source": [
    "#### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "217a9eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:26,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The mean score and the 95% confidence interval of the score estimate are\n",
      "Recall: 97.89 (+/- 10.19)\n",
      "Precision: 79.46 (+/- 21.73)\n",
      "F1-Score: 87.28 (+/- 16.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recallScores, precisionScores, f1Scores = funcCustomCVScore(fncp_X_train=X_new, \n",
    "                                                            fncp_y_train=y_new, \n",
    "                                                            fncpKFold=10,\n",
    "                                                            fncpBaseModel=RandomForestClassifier,\n",
    "                                                            fncpBaseModelParam=None,\n",
    "                                                            fncpScoreAverage='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e25f0",
   "metadata": {},
   "source": [
    "#### Test Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c189f86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "\n",
      "Recall Score :80.7%\n",
      "Precision Score :80.79%\n",
      "F1 Score :80.74%\n"
     ]
    }
   ],
   "source": [
    "fncpModelEvaluvate(fncpActual=y_test, \n",
    "                   fncpPredicted=predictedValues, \n",
    "                   fncpBoolHeatMap=False, \n",
    "                   fncpMultiClass=True,\n",
    "                   fncpAverageType='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df0ce5",
   "metadata": {},
   "source": [
    "## Random Forest - Balnaced Data with Optimum Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e0867",
   "metadata": {},
   "source": [
    "#### Grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8726e4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters are \n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "print(f'The hyperparameters are \\n{random_grid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c27f33",
   "metadata": {},
   "source": [
    "#### Random Search CV Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b0c991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start time : 27042021_162737\n",
      "\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Minutes taken to complete training : 52.43469251791636\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = classiRandomForest\n",
    "current_time = datetime.datetime.now(pytz.timezone('Asia/Bangkok')).strftime(\"%d%m%Y_%H%M%S\")\n",
    "modelFileName = 'cv_SMOTE_model_'+ current_time +'.sav'\n",
    "print(f'Model training start time : {current_time}\\n')\n",
    "rf_random = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=100, cv=3, verbose=3, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(X_new, y_new)\n",
    "\n",
    "# Saving Model #\n",
    "pickle.dump(rf_random, open(modelFileName, 'wb'))\n",
    "smote_loaded_model = pickle.load(open(modelFileName, 'rb'))\n",
    "print(f'Minutes taken to complete training : {(time.time() - start_time)/60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc3efaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully loaded the model!!!\n"
     ]
    }
   ],
   "source": [
    "### Loading Model ###\n",
    "fileName = 'cv_SMOTE_model_27042021_162737.sav'\n",
    "smote_loaded_model = pickle.load(open(fileName, 'rb'))\n",
    "print('Sucessfully loaded the model!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c6eec",
   "metadata": {},
   "source": [
    "Please note that I have used the default scoring method of Random Forest classifier which is “mean accuracy” for choosing the best model in Random Search CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e3abb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best \"n_estimators\" hyperparameter is: 400 \n",
      "The best \"min_samples_split\" hyperparameter is: 5 \n",
      "The best \"min_samples_leaf\" hyperparameter is: 1 \n",
      "The best \"max_features\" hyperparameter is: auto \n",
      "The best \"max_depth\" hyperparameter is: 90 \n",
      "The best \"bootstrap\" hyperparameter is: False \n"
     ]
    }
   ],
   "source": [
    "for key, val in smote_loaded_model.best_params_.items():\n",
    "  print(f'The best \"{key}\" hyperparameter is: {val} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bed54202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Important Feature\n",
      "\n",
      "                             importance\n",
      "f_age                          0.290446\n",
      "f_yearstoFirstFunding          0.179961\n",
      "f_SumCol                       0.121987\n",
      "f_FirstFundingToLastFunding    0.112692\n",
      "f_country_code_USA             0.103240\n",
      "venture                        0.079707\n",
      "seed                           0.050879\n",
      "funding_rounds                 0.034209\n",
      "f_Multi_Category               0.015881\n",
      "f_URL                          0.010998\n",
      "private_equity                 0.000000\n",
      "f_country_code_TTO             0.000000\n",
      "f_region_Boston                0.000000\n",
      "f_region_New York City         0.000000\n",
      "f_region_SF Bay Area           0.000000\n",
      "f_country_code_LIE             0.000000\n",
      "f_country_code_ZWE             0.000000\n",
      "f_country_code_MUS             0.000000\n",
      "f_country_code_OMN             0.000000\n",
      "f_country_code_COL             0.000000\n",
      "\n",
      "\n",
      "Bottom 20 Important Feature\n",
      "\n",
      "                                    importance\n",
      "f_market_Computer Vision                   0.0\n",
      "f_country_code_FRA                         0.0\n",
      "f_market_Quantified Self                   0.0\n",
      "f_country_code_CHN                         0.0\n",
      "f_country_code_CAN                         0.0\n",
      "convertible_note                           0.0\n",
      "debt_financing                             0.0\n",
      "f_market_Enterprise Purchasing             0.0\n",
      "f_market_Vending and Concessions           0.0\n",
      "f_market_Young Adults                      0.0\n",
      "f_market_Digital Rights Management         0.0\n",
      "f_market_QR Codes                          0.0\n",
      "f_market_Unifed Communications             0.0\n",
      "f_market_Content Delivery                  0.0\n",
      "f_market_Babies                            0.0\n",
      "f_market_Oil and Gas                       0.0\n",
      "f_market_Content Creators                  0.0\n",
      "f_market_Oil                               0.0\n",
      "f_market_Women                             0.0\n",
      "f_country_code_GBR                         0.0\n"
     ]
    }
   ],
   "source": [
    "### Feature Importance ###\n",
    "dfSMOTEImportantFeature = funcFeatureImportance(smote_loaded_model, X_train, fncpCV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d3d2ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:31, 15.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The mean score and the 95% confidence interval of the score estimate are\n",
      "Recall: 97.94 (+/- 9.84)\n",
      "Precision: 80.15 (+/- 21.50)\n",
      "F1-Score: 87.73 (+/- 15.79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recallScores, precisionScores, f1Scores = funcCustomCVScore(fncp_X_train=X_new, \n",
    "                                                            fncp_y_train=y_new, \n",
    "                                                            fncpKFold=10,\n",
    "                                                            fncpBaseModel=RandomForestClassifier, \n",
    "                                                            fncpBaseModelParam=smote_loaded_model.best_params_,\n",
    "                                                            fncpScoreAverage='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727c55e",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e2f032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted the values\n"
     ]
    }
   ],
   "source": [
    "smotePredictedValues = smote_loaded_model.best_estimator_.predict(X_test)\n",
    "print('Sucessfully predicted the values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b117a",
   "metadata": {},
   "source": [
    "#### Test Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1216772f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics\n",
      "\n",
      "Recall Score :80.72%\n",
      "Precision Score :80.62%\n",
      "F1 Score :80.65%\n"
     ]
    }
   ],
   "source": [
    "fncpModelEvaluvate(y_test, smotePredictedValues, fncpBoolHeatMap=False, fncpMultiClass=True,fncpAverageType='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4331c26",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc203ba",
   "metadata": {},
   "source": [
    "Until now we have only built the models and model evaluation helps us to\n",
    "- Quantify the performance of a model\n",
    "- Choose the best model among the models that we had built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703ad08",
   "metadata": {},
   "source": [
    "This step goes hand in hand with model building — we either tune the hyper-parameters of a model or build a new feature or drop a feature or build an entirely new model based on the current model’s performance. As explained earlier since this is a highly imbalanced data set, we will be using F1-Score to evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520c8d5",
   "metadata": {},
   "source": [
    "| Dataset | Model | Cross Validation - F1-Score | Test Dataset - F1-Score |\n",
    "| --- | --- | --- | --- |\n",
    "| Imbalanced Dataset |Dummy Classifier| 80.29% | 80.74% |\n",
    "| Imbalanced Dataset |Random Forest Classifier| 82.20% | 81.14% |\n",
    "| Imbalanced Dataset |Random Forest Classifier (Optimum parameters)| 81.19% | 80.66% |\n",
    "| Balanced Dataset |Dummy Classifier| 43.88% | 79.60% |\n",
    "| Balanced Dataset |Random Forest Classifier| 87.28% | 80.74% |\n",
    "| Balanced Dataset |Random Forest Classifier (Optimum parameters)| **87.73%** | **80.65%** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace4630b",
   "metadata": {},
   "source": [
    "The below table summarizes the metrics for the above models that we had built and we can see that **Random Forest model that was trained on a balanced data set with optimum hyper parameters chosen using Random Search CV has clearly won the race with the highest F1-score. We can say that this model will have a F1-Score of 87.73% in the production environment with 95% confidence.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c5246",
   "metadata": {},
   "source": [
    "Since the performance of the model is almost the same for both the training data set and testing data set, we can say that our model has the optimum point in the bias-variance trade-off graph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbobpcr",
   "language": "python",
   "name": "bbobpcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
